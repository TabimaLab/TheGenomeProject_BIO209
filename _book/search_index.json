[["index.html", "The Genome Project: Excercise Guidebook Chapter 1 BIOL209 (The Genome Project) Excercise Guidebook Additional information about the professor", " The Genome Project: Excercise Guidebook Javier F. Tabima Restrepo 2023-01-03 Chapter 1 BIOL209 (The Genome Project) Excercise Guidebook Welcome to The Genome Project! This document here will be the Laboratory notebook we will use throughout the term. You will find here all the exercises and resources we will use for the course Additional information about the professor Professor Tabima Restrepo is always reachable at jtabima@clarku.edu. Office hours are on Wednesday afternoons at Larsy 223, schedule by email. "],["unix-challenge.html", "Chapter 2 UNIX Challenge", " Chapter 2 UNIX Challenge Objectives To practice and remember basic coding skills that we will use during the semester. To refresh the basics of data analysis in the command line To re familiarize with the basic formats used in computational biology Download the Synechococcus sp. WH 8101 files: Syn_WH8101.asmb.fasta, Syn_WH8101.cds.fasta and Syn_WH8101.aa.fasta from the Canvas page and answer the following questions in an R Markdown file. PLEASE: Include the code used for each question as code blocks or you will get points taken away! How many lines are in each FASTA file? How many sequences are in each FASTA file? What kind of molecule is found in each FASTA file? Why are the Syn_WH101.asmb.fasta and Syn_WH101.cds.fasta files different to each other? Provide at least five different gene/protein names from the FASTA files in question Count the occurrence of each nucleotide (A, T, C, and G) in the Whole Genome Files (WGS) of WH8102 and compare it with the nucleotide content for the Coding Sequence file of WH8102 In which of the three files can you find the genes WP_174719562.1, WP_130130567.1, and WP_130130558.1 Find the function for the genes WP_130130185.1 and WP_130130145.1 in the Syn_WH8102.aa.fasta and add them in a R markdown table How many genes with the hypothetical protein function can you find in the Syn_WH8102.aa.fasta file? Provide two more protein functions (annotations) and the number of genes associated with them How would you extract all the information related to sequence names for each file? "],["fastq-files-and-understanding-read-qualities.html", "Chapter 3 FASTQ files and understanding read qualities 3.1 Sample distribution 3.2 Basic information and creating backups 3.3 Quality Control", " Chapter 3 FASTQ files and understanding read qualities Objectives To learn about the most commonly used types of files for genome sequencing: FASTQ files To understand the information included in FASTQ files To identify good quality and bad quality reads from genome sequencing datasets Today we will explore the previously Illumina sequenced genomes of the four Synechococcus samples the Ahlgren Lab has provided us to assemble and annotate. These genomes have been sequenced using the Illumina HiSeq platform, with Paired Ends and a read length of 150bp. Based on that information, answer the following questions: How many FASTQ files per sample do you expect (one FASTQ per sample or two FASTQ per sample)? Justify your answer. Do you expect all the reads to be of the same size? Which size? 3.1 Sample distribution As mentioned in class, we have three main samples sequenced: S165, S166 and S167. We will use S165 as an example this week and then you will have to present the results of S166 and S167 as part of your lab report. We will use Smaug for our data analyses. Smaug, or the Great Worm, is the supercomputer we use in the T lab for mycological evolution. All the data is available in Smaug, so please be careful with the data provided. To access Smaug you need to connect via http://140.232.222.154:8787/. The username to access Smaug is the same of your Clark ID, but without the @clarku.edu (i.e. My user is jtabima) The files are stored in a folder at /Smaug_SSD/BIOL209/raw_illumina_data/raw_reads/SAMPLE_NAME. EVERYTHING that you will do, run or program will be stored in those folders, so please be careful and DON’T ERASE THE GENOME FILES! 3.2 Basic information and creating backups Inside of your sample folders, you should be able to find the genomes in FASTQ format. What are the genome files? Add the names here In your home folder (cd ~) create a folder called Genome_backup_SAMPLE_NAME and copy the genome FASTQ files there. We know that FASTQ files are divided by four lines per each read: Sequence information DNA sequence Spacer Quality The Sequence information header (line 1) starts with a @, followed by a set of strings. The first set of strings, between the @ and a colon (:) is my sequence identifier. Each read starts with that ID. Using that information, answer the following questions: What is your sample’s sequence ID? Can you use this information to count the number of reads per sample? Add the code below and the result. (Remember, to look at a GZ file without uncompressing it, use the zcat command) Are the number of reads between file R1 and R2 the same? Was this expected? Justify your answer. Finally, summarize your results in this table: Sample Name Sequence ID Number of Reads in R1 Number of Reads in R2 030121_38 NB551394 2649963 2649963 S165 S166 S167 3.3 Quality Control High Throughput Sequencing technologies are not perfect. They can have various types of errors and contamination. Blindly using raw sequence data for downstream analysis is risky and will lead to poor, and/or inaccurate results. Here is a very helpful paper on how to “diagnose” issues with sequence data and how to improve these problems. Reading it will help you answers the questions and gain an understanding of common problems with high-throughput sequencing: Zhou, X. and Rokas, A., 2014. Prevention, diagnosis and treatment of high‐throughput sequencing data pathologies. Molecular ecology, 23(7), pp.1679-1700. The paper is available in the Canvas page of BIOL209 as well. 3.3.1 Evaluating QC of FASTQ using FastQC To evaluate the quality of our data and to “diagnose” any problems, we will use software called FastQC. This webpage can be used to learn more about each metric presented in the FastQC output: http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/ 3.3.1.1 Running FastQC Create a directory within you sample folder called QC Running FastQC is super easy, just use the following command for each of your FASTQ files /Smaug_SSD/bin/fastqc -o /your/output/directory/ sequence.file.fastq.gz Answer the following question: What are the outputs of FastQC? Download the .html files to your local machine (i.e. your computer). The files should be readable by any Internet Browser. 3.3.1.2 Analizing and describing results Once you’ve transferred the .html files to your computer, open it up in a web browser. You should see a nicely arranged page with 12 analyses (see the site for an example: https://www.bioinformatics.babraham.ac.uk/projects/fastqc/). Each of these analyses can tell us something about the quality of our data. Answer the following questions: How many sequence reads makeup our dataset? Does this agree with your previous calculation? What is the read length of our data? Is this result expected or do we see weird results? What is the GC content of our data? Does this match expectations? Describe the sequence quality of the files (per base sequence quality, per tile sequence quality, per sequence quality score). In general, are the forward and reverse reads of similar quality? If they differ, how do they differ? Are there any issues with the various other metrics analyzed by FastQC (i.e. the red circles with the ‘X’ on the left under the ‘Summary’ heading)? Do you notice any patterns that are puzzling or troubling with any of these analyses? Improving the Illumina Data: Outline rough plan to improve the Illumina Sequence data. You don’t need to provide specific program commands and parameters, but do take a look at some of the programs above to start thinking about how you would improve or filter the read data. By all means you can consider using other software if you find something interesting or useful. "],["laboratory-techniques-for-dna-extraction.html", "Chapter 4 Laboratory techniques for DNA extraction", " Chapter 4 Laboratory techniques for DNA extraction "],["improving-illumina-read-quality.html", "Chapter 5 Improving Illumina Read Quality 5.1 Running Trimmomatic 5.2 Evaluating quality of processed reads 5.3 Requirements for processing your reads 5.4 What to turn in?", " Chapter 5 Improving Illumina Read Quality Objectives and goal The goal of this challenge is to properly process the Illumina data in preparation for genome assembly. You work in your lab groups and use forward and reverse reads to completely remove and/or trim parts of the reads that are low quality and problematic while still maintaining the highest number of sequence data as possible. How you decide to process, trim, and filter your reads is up to you. I’d recommend you use Trimmomatic, which can be found at /Smaug_SSD/bin/Trimmomatic-0.39/trimmomatic-0.39.jar within Smaug, but if you want to write your own custom scripts feel welcome to do so. Be sure to consider the problems that came to light in the quality analysis from Lab 2. The key to this challenge is in how you use the various settings of available programs. Take a careful look at the manual pages for these tools to take advantage of all of their capabilities. 5.1 Running Trimmomatic I recommend you all check the slides of the Short read sequencing class as they have visual instructions on how to use Trimmomatic. Check the options!! To run trimmomatic in the cluster, modify the following template: java -jar /Smaug_SSD/bin/Trimmomatic-0.39/trimmomatic-0.39.jar PE -T 1 R1.fastq.gz R2.fastq.gz Processed_R1.fastq.gz Processed_R1.Unpaired.fastq.gz Processed_R2.fastq.gz Processed_R2.Unpaired.fastq.gz OPTIONS_FOR_TRIMMING Example for Illumina clip: java -jar /Smaug_SSD/bin/Trimmomatic-0.39/trimmomatic-0.39.jar PE -threads 1 NBP03_S165_R1_001.fastq.gz NBP03_S165_R2_001.fastq.gz IlluminaTrim_R1.fastq.gz IlluminaTrim_R1.Unpaired.fastq.gz lluminaTrim_R2.fastq.gz lluminaTrim_R2.Unpaired.fastq.gz ILLUMINACLIP:/Smaug_SSD/bin/Trimmomatic-0.39/adapters/TruSeq3-PE.fa:2:30:10:2:True Check the trimmomatic web page for more info: https://github.com/usadellab/Trimmomatic I also expect you ask about what is an unpaired read and why are they part of the output. 5.2 Evaluating quality of processed reads The team with the largest number of bases mapped to the reference genome of Synechococcus sequenced by the 2019 BIOL209 course will ‘win’ the competition. The srefernece sequence can be found at /Smaug_SSD/BIOL209/Reference_Syn/GCA_013133755.1_ASM1313375v1_genomic.fasta. We will evaluate the results on next week’s lab. However, if you want to evaluate the quality and quantity of your resulting fastq files, you must run a read alignment against the BIOL209 reference genome. I suggest that you test out your pipeline then run the mapping program to evaluate you results. Try different settings and repeat until you’re satisfied. Please be mindful of the space you are taking up in your folders, as the intermediate fastq files you generate for multiple tests and steps can add up. Please consider deleting any .fastq data along the way that you no longer need. After the exercise is complete, I’ll ask you delete any extraneous fastq files as well. Below is the command that you must use to generate the mapping output and evaluate the quantity of your resulting reads. The program is called BBMap (https://jgi.doe.gov/data-and-tools/bbtools/). We will learn more about read mapping in the upcoming weeks, but for this lab please use the following script: Note: Be sure to copy the reference genome to a folder in your own account directory for bbsplit to work properly as it will generate a folder to store reference info. /Smaug_SSD/bin/bbmap/bbmap.sh in=Processed_R1.fastq.gz in2=Processed_R2.fastq.gz ref=GCA_013133755.1_ASM1313375v1_genomic.fasta minid=0.90 threads=16 statsfile=stats_out.txt Check the stats_out.txt file as it will include your results as such: Read 1 data: pct reads num reads pct bases num bases mapped: 0.4267% 8726 0.4267% 2181500 5.3 Requirements for processing your reads To make fair comparisons, the processing of your reads must meet these requirements: All processed reads must have a minimum length of 36 bp. Use a minimum read Phred quality score cutoff of 20. 5.4 What to turn in? Grading will be based on you providing: The commands for your sequence processing pipeline The updated HTML of FASTQC before and after processing the reads The location of your processed reads within Smaug The output of BBmap’s statsfile "],["nanopore-sequencing.html", "Chapter 6 Nanopore Sequencing 6.1 Summarizing our Nanopore sequencing", " Chapter 6 Nanopore Sequencing 6.1 Summarizing our Nanopore sequencing Within the /Smaug_SSD/BIOL209/nanopore_raw_data folder you will find a report_Nanopore_YOURSAMPLE.pdf file. Download it and open it. Answer the following questions: How many reads were generated by your Nanopore run? How many bases passed the quality filters? Based on the Read Length Histogram Basecalled Bases figure, what was your N50? Based on your Read Length Histogram Basecalled Bases, what was the length of the longest read you sequenced? Based on the Mux Scan Grouped figure, what was the maximum number of Active pores (green bars) in your run? What time? Based on the QScore figure, do you see a decrease in quality over time? Based on the output by the Run Debug Messages, what was the initial number of available pores? What was the minimum number of available pores? "],["assembly-methods-for-short-read-sequencing.html", "Chapter 7 Assembly Methods for Short Read Sequencing 7.1 Comparing between k-mers in genome assembly 7.2 Using a multi-K-mer approach to avoid manual k-mer selection 7.3 Cleaning the assembly and detecting contamination 7.4 Coverage and Taxonomy detection assay 7.5 Extracting the scaffolds of interest", " Chapter 7 Assembly Methods for Short Read Sequencing Objectives Recommended: Create a folder inside of your data folder called assembly and run everything there. 7.1 Comparing between k-mers in genome assembly First, lets test different k-mers and observe how it affects the assembly. We will use SPADES, one of the best assemblers available currently, to assemble our data. Using your cleaned and raw reads, choose one of the following K values (7, 21, 47) and run SPADES by modifying the following code python3 /Smaug_SSD/bin/SPAdes-3.13.0-Linux/bin/spades.py -t 3 -k k_value -1 paired_ends_R1.fastq.gz -2 paired_ends_R2.fastq.gz -o spades_k_value Check the stats of your assembly by using the stats.sh program from BBMAP as such: stats.sh in=spades_k_value/scaffolds.fasta Fill the following table. Dataset K-value Number of scaffolds %GC N50 Raw reads 7 Raw reads 21 Raw reads 47 Cleaned reads 7 Cleaned reads 21 Cleaned reads 47 Answer the following questions: Define Kmer using your own words Define N50 and L90 using your own words Based on your results and the table you filled, what is the best K-mer value? 7.2 Using a multi-K-mer approach to avoid manual k-mer selection As we can tell, K-mer size affects tje assemblies. That means we will have to test multiple K-mer values to find which combination of k-mers is the best one for our assembly. Luckily, there are programs that will choose the number of optimal k-mers to be tested and will select the best assembly as a final product. Unicycler is an assembly program that doesn’t exactly that. Its a program that is specific for prokariotic organisms, so it fits our genomes perfectly. The Unicycler program is super cool as it uses a lot of different programs (such as SPADES, Racon, Pilon and others) to optimize the assemblies for bacterial/archaeal organisms. Run Unicycler for your clean and raw reads by modifying the following command: unicycler -1 paired_ends_R1.fastq.gz -2 paired_ends_R2.fastq.gz -o unycycler_raw/clean After the assembly has finished, evaluate the scaffolds using stats.sh and create a table below with the results. Answer the following questions: What was the best K-mer value selected by Unicycler? What assembly was better? Any of the SPADES assemblies or the Unicycler? We can calculate the coverage for the best assembly by using bwa to map the reads to our best assembly as such: bwa index best_assembly.fasta bwa mem -t 4 best_assembly.fasta paired_ends_R1.fastq.gz paired_ends_R2.fastq.gz | samtools view -S -b | samtools sort -O bam -o mapped.bam samtools index mapped.bam Where best_assembly.fasta is your selected assembly, and your output is mapped.bam. We will learn more about bam files later on the course. And then, use the pileup.sh program to summarize the coverage results as such: pileup.sh in=mapped.bam out=stats.txt Create a table summarizing the best assembly with coverage information: Dataset Assembly software Number of reads Number of scaffolds %GC N50 L90 Average coverage 7.3 Cleaning the assembly and detecting contamination So, you think we have the best assembly? NOPE. We still have some work to do. We have a little problem with our data, and that is that these bacteria might have grown with some other species. So, chances are the DNA extraction also includes other bacteria that are not Synechococcus. How can we check this? A. We do a Sketch assay that will tell us if there is DNA from other species in our genomes B. We do a coverage and taxonomy detection assay to determine the number and type of contaminants We will be doing both in this laboratory assignment. 7.3.1 Sketch assay A Sketch assay is a method of rapidly comparing your assembly results k-mers against databases populated with different reference organisms (such as RefSeq from NCBI). The method it uses is to create a hash. A Hash is a function that converts a large object into a smaller one. Then, you compare this hashes against the hashes from the reference databases to see what your genome looks like. This means that you can see if your genome has contamination from other organisms very rapidly. Lets do a sketch assay for the assemblies: Obtain the sketch for your assembled genome and compare it against the sketch of the RefSeq datasets using sendsketch.sh as such: sendsketch.sh in=best_assembly.fasta refseq Check the results of the program. The columns WKID KID ANI SSU Complt Matches Unique represent the Weighted k-mer identity, K-mer identity, Average nucelotide identity, 16S identity by alignment, Genome completeness, The number of shared kmers between query and ref, The number of shared kmers between query and ref, and no other ref. So, if your result is 100% in the WKID against Synechococcus, that means that 100% of the k-mers from your assembly match the k-mers from Synechococcus. Answer the following questions: What are the GENUS with higher WKID scores? What is the WKID score of your assembly when compared to Synechococcus? Summarize you results and what they mean 7.4 Coverage and Taxonomy detection assay Before we start do this: conda init bash Then, log out and log in again. Now we suspect that our sequences have a lot of environmental contaminants, but we don’t know which of the scaffolds are from our bacteria of interest or which ones are from contaminants. This is because the results from the sendsketch.sh assay are across the entire assembly.To have a good assemblythat only respresnets our species of interest we should identify and remove all scaffolds that are not matching the taxa we are interested in. To do this, we use blobtools. Blobtools determines the taxonomic assignment and the coverage for every single scaffold in your assembly! Blobtools needs three files: Your assembly in FASTA format Your BAM file with mapped reads to your best assembly (mapped.bam). This will assess the coverage for each scaffold, as contaminant scaffolds tend to have a different coverage than scaffolds from our species of interest. A NCBI BLAST table where each scaffold is compared to the NCBI database. This will tell us the taxonomic assignment of each scaffold. Then, blobtools will put all the information together and provide us with two main results: A list of the taxonomic assignment and coverage of each scaffold A plot that shows the taxonomic assignment and coverage of each scaffold Let’s, then, use blobplots and create the taxonomic and coverage assay for our assembled scaffolds. As of now, we have two files: - Your assembly in FASTA format - Your BAM file with mapped reads to your best assembly (mapped.bam) from step 8 in this lab We are missing the BLAST taxonomic assignments Do a BLAST search of our scaffolds against NCBI’s nt database by first creating a new folder called blobtools and running everything there: mkdir blobtools cd blobtools blastn -num_threads 4 -task megablast -query best_assembly.fasta -db nt -outfmt &#39;6 qseqid staxids bitscore std&#39; -max_target_seqs 1 -max_hsps 1 -evalue 1e-25 -out best_assembly.blast Where best_assembly.fasta is you assembly file, -db is the nt database from NCBI Answer the following questions using your knowledge from MBB 101 What blast program are we using and what does it mean? What is the nt database? What do the -max_target_seqs and -max_hsps flags mean? What is the e-value used as threshold? What does e-value mean? Now, after BLAST is done we have all the elements to run blobltools as such: blobtools create -i best_assembly.fasta -b mapped.bam -t best_assembly.blast -o blobltools_out Where -i is your assembly, -b is the BAM file of reads mapped to the assembly, -t is the BLAST output, and -o is the output name for the run. Blobtools needs a two additional steps in order to visualize and plot the results as this: blobtools view -i blobltools_out.blobDB.json; blobtools plot -i blobltools_out.blobDB.json Let’s download the plots in the .png files. the blobtools_out.blobDB.json.bestsum.phylum.p8.span.100.blobplot.read_cov.bam0.png shows the percentage of all taxonomic assignments in our scaffold. Answer the following questions: Include the image. What is the taxonomical unit with the highest percentage of scaffolds in our assembly? What is the percentage of scaffolds with assignment to Synechococcus? The blobtools_out.blobDB.json.bestsum.phylum.p8.span.100.blobplot.bam0.png file is a blobplot that shows three main things: In Top: A length (span) vs. GC content plot that shows the size of each scaffold versus its GC content. The colors represent the taxonomic assignment In the middle: A Bubbleplot of coverage vs GC content for each scaffold. Larger the circle, larger the scaffold. The colors represent the taxonomic assignment In the right: A coverage vs. length (span) plot that shows the coverage of each scaffold versus its length The colors represent the taxonomic assignment What this plot shows us is the differences between all the scaffolds assembled. We can see, here, how the contaminants look versus our desired sequence. Answer the following questions: Include the image. What can you say about this plot? Back in the cluster, check the blobtools_out.blobDB.json.bestsum.phylum.p8.span.100.blobplot.stats.txt file. That file contains a summary of all the stats from blobtools. Copy and paste the results into this page: https://www.tablesgenerator.com/markdown_tables and copy and paste the result below: Add table here Here’s what each column means: name: Best taxonomic hit colour: Color used for the plots count_visible: Number of scaffolds associated with the taxonomic hit count_visible_perc: Percentage of assembly scaffolds associated with the taxonomic hit span_visible: Number of bases associated with the taxonomic hit span_visible_perc: Percentage of total bases associated with the taxonomic hit n50: N50 per taxonomic hi gc_mean: Mean GC content per taxonomic hit gc_std: Standard deviation of GC content per taxonomic hit bam0_mean: Mean coverage per taxonomic hit bam0_std: Standard deviation of coverage per taxonomic hit bam0_read_map: Number of reads mapped to the taxonomic hit bam0_read_map_p: Percentage of reads mapped to the taxonomic hit Answer the following questions: What is the most represented taxonomic hit in your dataset? How did you come to that conclusion? What about our Cyanobacteria? Can you summarize the results in your own words? Finally, to clean the assembly we will extract the scaffolds that match Cyanobacteria. The information of the taxonomic assignment for each scaffold is found in the blobtools_out.blobDB.table.txt. Open the first 20 lines of the file using the program of your choice. Here’s what each column mean: name: Name of the sequence length: Total length of the sequence, i.e. count(A, G, C, T, N) GC: GC content percentage of the sequence, i.e. count(G, C)/count(A, G, C, T) N: Number of N’s in the sequence, i.e. count(N) bam0: Coverage from bam0 (see main header for filename) phylum.t.6%s: The assigned taxonomy of the sequence at the taxonomic rank of “phylum” under the tax-rule “best-sum” phylum.s.7%s: The sum of scores for the taxonomy of the sequence at the taxonomic rank of “phylum” under the tax-rule “best-sum” phylum.c.8: The c-index for the taxonomy of the sequence at the taxonomic rank of “phylum” under the tax-rule “best-sum” Answer the following question: How can you use this file to extract the scaffolds of interest? 7.5 Extracting the scaffolds of interest The final step of our assembly is to extract all the scaffolds that have cyanobacterial associations. We can extract those scaffolds by using the blobtools seqfilter program. This program can be ran as such: blobtools seqfilter -i FASTA -l LIST -o PREFIX &gt; Cynaobacteria_scaffolds.fasta blobtools seqfilter -i assembly.fasta -l bplot/cyano_scaffs.txt -o Cyano_scaffold Where -i is your assembly, -l is the list of sequence names you want to extract, and -o is the new names for the new assembly. So, we have the -i and -o elements. Answer the following question: Using the command line tools we have learnt before, how do we extract everything that is Cyanobacteria from the blobtools_out.blobDB.table.txt to create the required file by -l? (Hint, use the grep and cut commands in a pipe.) This is an example of how the file should look like: $ head list_of_cyano_scaffolds.txt 4 8 21 30 34 Run the blobtools seqfilter command and extract the cyanobacterial reads. Then use the stats.sh command in the new extracted files (your final assembly). What are the stats? Create a table below. Finally, how can you check rapidly that there is no contamination in the new assembly? (Hint: Use a program that compares sketches). Paste the result below. Summarize your final assembly in your own words: "],["hybrid-assembly-methods-for-short-and-long-reads.html", "Chapter 8 Hybrid Assembly Methods for Short and Long Reads 8.1 Hybrid assembly using Unicycler", " Chapter 8 Hybrid Assembly Methods for Short and Long Reads Objectives In the modern era of cheaper sequencing and easily accessible genome sequencers, we can also include long reads in our assembly. The long reads will provide the assemblers with longer regions in which the different fragments can anchor and connect, creating, in theory, longer scaffolds and a more complete assembly. Conversely, these long reads usually have lower quality than short reads and they are less abundant, so using them by themselves may lead to an assembly with a larger percentage or errors than, for example, an assembly with only short reads. So, the best of both worlds can be combined into what we call hybrid assemblies. Hybrid assemblies use both short and long reads to produce a high quality assembly (compred to an assembly of long reads only) with longer and fewer scaffolds than assemblies done with only short reads. To perform hybrid genome assemblies, we need two main files: Our Illumina reads (Choose between raw reads or cleaned reads) Our Nanopore reads (Located at the /Smaug_SSD/BIOL209/nanopore_raw_data folder) 8.1 Hybrid assembly using Unicycler The program unicycler is combination of programs (also called a pipeline) to perform a hybrid assembly. Usually, a manual hybrid assembly (i.e. using each program separately) entails the following steps: Spades to make the short reads assemblies miniasm and racon to bridge between the scaffolds from the short read assemblies bwa or bowtie to map the reads to the new elongated scaffolds for error control pilon to correct the errors detected by the previous read mapping step However, for prokariotic organisms as the ones we are trying to assemble, our Unicycler program will do everything mentioned above and more, so hopefully we will have the best assambly possible using the highest amount of data. To run Unicycler with the long read and short read datasets, modify the following command with your FASTQ reads: unicycler -1 paired_ends_R1.fastq.gz -2 paired_ends_R2.fastq.gz -l Nanopore_reads.fastq.gz -o long_read_assembly Let Unicycler run. Answer the following questions: Fill the following table using the information from the hybrid assembly and your previous best short read assembly (Hint: use the output from stats.sh): Source Number of scaffolds %GC N50 L90 Short read assembly Hybrid assembly Use a Sketch assay to determine the taxonomic markup of your long read assembly and answer the following questions for the hybrid assembly: What are the GENUS with higher WKID scores? What is the WKID score of your assembly when compared to Synechococcus? Summarize you results and what they mean Use blobtools to identify the taxonomic markup of your long read assembly and answer the following questions (Only map your short reads to the new assembly. Remember to use the bwa index long_read_assembly.fasta before you map the reads using bwa mem) Include the image here: What is the taxonomical unit with the highest percentage of scaffolds in our assembly? What is the percentage of scaffolds with assignment to Synechococcus? Finally, extract all the contigs/scaffolds with Cyanobacteria ID. Save these scaffolds in a file called final_cyano_assembly.fasta Map the short reads to the final_cyano_assembly.fasta using BWA. NOTE: Please remember to do the bwa index final_cyano_assembly.fasta code Use the pileup.sh program to summarize the coverage results. Save the number of mapped reads and the percentage of reads mapped. We will do a similar thing using long reads. However, BWA is only used for short reads. The creators of BWA made a long read mapper called minimap2. minimap2 maps the reads and creates a BAM file like in BWA but using the long reads. Lets use it to see our coverage with the long read data: minimap2 -a final_cyano_assembly.fasta Nanopore_reads.fastq.gz |samtools view -S -b | samtools sort -O bam -o long_read_mapped.bam Where the -a means create a SAM file that will be converted into a BAM file. Use the pileup.sh program to summarize the coverage results and fill the following table. Dataset Number of reads Percentage of mapped reads Average coverage Short read assembly Hybrid assembly Did your long reads help improve the assembly? Justify your answer. "],["references.html", "References", " References "],["gene-prediction-methods.html", "Chapter 9 Gene Prediction Methods 9.1 Installing prokka 9.2 Annotating the genomes using prokka", " Chapter 9 Gene Prediction Methods Objectives After assembling the genome, we need to identify which regions are genes. This is called gene annotation or gene prediction, and uses a combination of ab-initio approaches with homology-based searches to predict and annotate the genes. We will use prokka, a state-of-the-art program for prokariotic genome annotation. This program uses both approaches to predict genes. 9.1 Installing prokka #*# Installing miniconda Before we can start installing prokka, we need to create a computational environment for it to be able to run correctly. Miniconda provides that environment by creating a python instance that groups all the requirements for these programs to run. PLEASE LET ME KNOW IF THESE STEPS DONT WORK. INSTALLING CONDA CAN BE ANNOYING! bash /Smaug_SSD/bin/Miniconda3-latest-Linux-x86_64.sh Say yes to all the prompts, and let miniconda install. Then, close your window and reconnect to Smaug. 9.1.1 Installing the prokka environment and program After logging back in, we need to install Prokka using miniconda as following: bash conda init bash log out and log in again, and then: bash conda create -n prokka_env -c conda-forge -c bioconda prokka conda activate prokka_env We can finally run prokka. Test it by running prokka A long prompt shoud appear. 9.2 Annotating the genomes using prokka Usually, these computationally complex programs are very long and cumbersome to run, but the develkopers of prokka have made it super easy to run. Within your sample folder, run the following code: prokka --genus Synechoccocus --strain the_name_of_your_strain --outdir your_sample_name_annotation --prefix your_sample_name your_assembly.fasta And let it run! 9.2.1 Summarizing the results from prokka After prokka is done, the outputs should be in your your_sample_name_annotation folder. Using the head command, answer the following question: Check the .fna, .fsa, .ffn, .faa, .gff, .tbl, .tsv, and .gbk files and explain what are their contents below: .fna file: .fsa file: .ffn file: .faa file: .gff file: .tbl file: .tsv file: .gbk file: Hint: Check the Prokka manual Using your knowledge on the command line, can you count the number of predicted proteins, translated CDS sequences and all the prediction transcripts (CDS, rRNA, tRNA, tmRNA, misc_RNA) Open the .txt file. Answer the following questions: How many CDS are found? Do they match your counts from the previous step? Define rRNA, tRNA and tmRNA (cite your references please) and present the counts of each RNA type. Using the head command, describe the columns of your .gff file. Use the following code to create a summary table of your functional annotations: cut -f 7 your_sample_name.tsv | sort | uniq -c | sort -nr &gt; gene_counts.txt Open the gene_counts.txt file and answer the following questions: What is the most abundant gene prediction? What is the most abundant gene prediction that is not a hypothetical/predicted protein? What are the most common five gene annotations in your genome? Finally, select three random hypothetical proteins from your faa file. Run them in InterPro Scan (https://www.ebi.ac.uk/interpro/search/sequence/). Answer the following: Did any of these proteins have an annotation? Add it below. Add the path of your faa file here: "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
